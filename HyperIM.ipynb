{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import geoopt as gt\n",
    "\n",
    "from net.HyperIM import HyperIM\n",
    "from util import train, evalu, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dtype = th.float64\n",
    "th.set_default_dtype(default_dtype)\n",
    "\n",
    "if th.cuda.is_available():\n",
    "    cuda_device = th.device('cuda:0')\n",
    "    th.cuda.set_device(device=cuda_device)\n",
    "else:\n",
    "    raise Exception('No CUDA device found.')\n",
    "    \n",
    "data_path = './data/sample/'\n",
    "\n",
    "# for the sample\n",
    "label_num = 103\n",
    "vocab_size = 50000\n",
    "word_num = 200\n",
    "\n",
    "if_gru = True # otherwise use rnn\n",
    "if_log = True # log result\n",
    "\n",
    "epoch = 1\n",
    "embed_dim = 10\n",
    "\n",
    "train_batch_size = 50\n",
    "test_batch_size = 50\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape torch.Size([50, 200]) y_train shape torch.Size([50, 103])\n",
      "train_batch_num 40\n",
      "X_test shape torch.Size([50, 200]) y_test shape torch.Size([50, 103])\n",
      "test_batch_num 4\n"
     ]
    }
   ],
   "source": [
    "# use pre-trained embed if avalible    \n",
    "word_embed = th.Tensor(vocab_size, embed_dim)\n",
    "label_embed = th.Tensor(label_num, embed_dim)\n",
    "\n",
    "net = HyperIM(word_num, word_embed, label_embed, hidden_size=embed_dim, if_gru=if_gru)\n",
    "net.to(cuda_device)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optim = gt.optim.RiemannianAdam(net.parameters(), lr=lr)\n",
    "\n",
    "train_data_loader, test_data_loader = data.load_data(data_path, train_batch_size, test_batch_size, word_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "batch: 0it [00:00, ?it/s]\u001b[A\n",
      "batch: 1it [00:06,  6.18s/it]\u001b[A\n",
      "batch: 2it [00:11,  5.92s/it]\u001b[A\n",
      "batch: 3it [00:16,  5.76s/it]\u001b[A\n",
      "batch: 4it [00:23,  6.05s/it]\u001b[A\n",
      "batch: 5it [00:29,  6.00s/it]\u001b[A\n",
      "batch: 6it [00:35,  6.02s/it]\u001b[A\n",
      "batch: 7it [00:41,  6.01s/it]\u001b[A\n",
      "batch: 8it [00:47,  6.05s/it]\u001b[A\n",
      "batch: 9it [00:53,  6.05s/it]\u001b[A\n",
      "batch: 10it [00:59,  6.00s/it]\u001b[A\n",
      "batch: 11it [01:05,  6.00s/it]\u001b[A\n",
      "batch: 12it [01:11,  5.96s/it]\u001b[A\n",
      "batch: 13it [01:17,  5.99s/it]\u001b[A\n",
      "batch: 14it [01:23,  5.96s/it]\u001b[A\n",
      "batch: 15it [01:29,  5.94s/it]\u001b[A\n",
      "batch: 16it [01:35,  5.91s/it]\u001b[A\n",
      "batch: 17it [01:41,  5.96s/it]\u001b[A\n",
      "batch: 18it [01:47,  5.95s/it]\u001b[A\n",
      "batch: 19it [01:53,  5.96s/it]\u001b[A\n",
      "batch: 20it [01:59,  5.98s/it]\u001b[A\n",
      "batch: 21it [02:05,  5.95s/it]\u001b[A\n",
      "batch: 22it [02:11,  6.00s/it]\u001b[A\n",
      "batch: 23it [02:16,  5.79s/it]\u001b[A\n",
      "batch: 24it [02:21,  5.51s/it]\u001b[A\n",
      "batch: 25it [02:26,  5.37s/it]\u001b[A\n",
      "batch: 26it [02:31,  5.28s/it]\u001b[A\n",
      "batch: 27it [02:36,  5.17s/it]\u001b[A\n",
      "batch: 28it [02:41,  5.11s/it]\u001b[A\n",
      "batch: 29it [02:46,  5.03s/it]\u001b[A\n",
      "batch: 30it [02:51,  4.97s/it]\u001b[A\n",
      "batch: 31it [02:56,  4.99s/it]\u001b[A\n",
      "batch: 32it [03:00,  4.95s/it]\u001b[A\n",
      "batch: 33it [03:05,  4.97s/it]\u001b[A\n",
      "batch: 34it [03:11,  5.07s/it]\u001b[A\n",
      "batch: 35it [03:16,  5.22s/it]\u001b[A\n",
      "batch: 36it [03:22,  5.27s/it]\u001b[A\n",
      "batch: 37it [03:27,  5.37s/it]\u001b[A\n",
      "batch: 38it [03:33,  5.38s/it]\u001b[A\n",
      "batch: 39it [03:38,  5.44s/it]\u001b[A\n",
      "train epoch: 100%|██████████| 1/1 [03:43<00:00, 223.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 \tloss 26.941045098798682\n"
     ]
    }
   ],
   "source": [
    "train.train(epoch, net, loss, optim, if_neg_samp=False, train_data_loader=train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 4it [00:06,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\t49.000\t\tP@3\t33.500\t\tP@5\t27.300\n",
      "nDCG@1\t49.000\t\tnDCG@3\t40.526\t\tnDCG@5\t44.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evalu.evaluate(net, if_log=if_log, test_data_loader=test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
